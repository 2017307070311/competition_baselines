# 2021海华AI挑战赛·中文阅读理解·技术组 BaseLine 分享

## 赛道链接

https://www.biendata.xyz/competition/haihua_2021/

## 赛道背景

机器阅读理解(Machine Reading Comprehension)是自然语言处理和人工智能领域的前沿课题，对于使机器拥有认知能力、提升机器智能水平具有重要价值，拥有广阔的应用前景。机器的阅读理解是让机器阅读文本，然后回答与阅读内容相关的问题，体现的是人工智能对文本信息获取、理解和挖掘的能力，在对话、搜索、问答、同声传译等领域，机器阅读理解可以产生的现实价值正在日益凸显，长远的目标则是能够为各行各业提供解决方案。

## 比赛任务

本次比赛技术组的数据来自中高考语文阅读理解题库。每条数据都包括一篇文章，至少一个问题和多个候选选项。参赛选手需要搭建模型，从候选选项中选出正确的一个。

以下是训练集中的两个例子：

```
  {
    "ID": 1,
    "Content": "奉和袭美抱疾杜门见寄次韵  陆龟蒙虽失春城醉上期，下帷裁遍未裁诗。因吟郢岸百亩蕙，欲采商崖三秀芝。栖野鹤笼宽使织，施山僧饭别教炊。但医沈约重瞳健，不怕江花不满枝。",
    "Questions": [
      {
        "Question": "下列对这首诗的理解和赏析，不正确的一项是",
        "Choices": [
          "A．作者写作此诗之时，皮日休正患病居家，闭门谢客，与外界不通音讯。",
          "B．由于友人患病，原有的约会被暂时搁置，作者游春的诗篇也未能写出。",
          "C．作者虽然身在书斋从事教学，但心中盼望能走进自然，领略美好春光。",
          "D．尾联使用了关于沈约的典故，可以由此推测皮日休所患的疾病是目疾。"
        ],
        "Answer": "A",
        "Q_id": "000101"
      }
    ]
  },
  {
    "ID": 2,
    "Content": "隆冬之际，西伯利亚的寒流（笼罩/席卷）欧亚大陆，狂风肆虐，草木凋凌，而那些春天的元素——温暖、雨水、绿叶、鲜花，都集结在位于热带的海南岛。海南岛就像是一艘花船，（系/停）在雷州半岛上，满载寒冬大陆的梦幻和想象。每年，从广州向漠河，春天昼夜兼程，都要进行一次生命版图的（扩展/扩充）。他像赤足奔跑的孩子，一路上用稚嫩的声音轻轻呼唤，于是万物苏醒，盛装应和，可谓“东风好作阳和使，      。”迢迢旅途中，气候的巨大差异，导致众多物种中只能有限地参与这一盛会。木棉花花朵硕大，是南国花中豪杰，“一声铜鼓催开，千树珊瑚齐列，”但她终究无法走出岭南。当春天行经长江、黄河流域时，出场的是桃花、杏花等新主角，“桃花嫣然出篱笑，          ”，然而她们却无法追随春天深入雪国，陆续抱憾退出，随后登场的便是白杨、连翘等北国耐寒植物。",
    "Questions": [
      {
        "Question": "1. 文中“肆虐”“凋凌”“昼夜兼程”“版图”“稚嫩”“嫣然”“抱憾退出”的词语中，有错别字的一项是",
        "Choices": [
          "A. 肆虐  凋凌",
          "B. 集结  昼夜兼程",
          "C. 版图  稚嫩",
          "D. 嫣然  抱憾退出"
        ],
        "Answer": "A",
        "Q_id": "000201"
      },
      {
        "Question": "依次选用文中括号里的词语，最恰当的一项是",
        "Choices": [
          "A. 席卷  系  扩展",
          "B. 笼罩  停  扩展",
          "C. 席卷  停  扩充",
          "D. 笼罩  系  扩充"
        ],
        "Answer": "A",
        "Q_id": "000202"
      }
    ]
  }
```

可以得到几个初步的结论：

1. 题目本身对于普通人类来说难度也很大 (参考高考语文试题)
2. 文本长度有相当一部分题目较长( > 512)
3. 有部分文言文，可能对 BERT 等预训练模型有难度

## BaseLine

huggingface/transformers 的 examples 里有个 multiple-choice 的例子：

https://github.com/huggingface/transformers/tree/master/examples/multiple-choice

可以直接拿来用，不过需要按以下思路来处理：

1. 将本赛道的数据格式 hard-code 成 SWAG 数据集的格式；
2. run_swag.py 没有 do_predict 部分，需要修改添加；
3. 参数需要微调 (特别是显存吃紧的情况下，记得添加 gradient_accumulation_steps 参数)

本 Baseline 提供了修改好的 run_swag.py，将 haihua 数据集放在 raw_data 目录内，然后直接运行 run_swag.ipynb 即可完成训练并生成 submission 文件。

预训练模型：hfl/chinese-roberta-wwm-ext, lr=2e-5, 5 epochs
运行环境：ubuntu-1804，2080Ti，5 epochs 训练集:验证集 = 13000:2425 划分，大概两个半小时完成。
线上分数：41.9394435351882

## TODO：

从 eval 结果来看过拟合有点严重
